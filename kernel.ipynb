{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "d14b5cfa-a0e3-4e14-897e-16b0cc186c0c",
        "_uuid": "7c448bc30163ab2af6f6ffcbd1762915d70ec327"
      },
      "cell_type": "markdown",
      "source": "![](http://)**Detecting Pneumonia in X-Ray Images**"
    },
    {
      "metadata": {
        "_cell_guid": "688d9d6c-b38e-4121-8bc0-33ffccc757bd",
        "_uuid": "5b08e4c16f36b20700a9334f4a8f7bfb1906105f"
      },
      "cell_type": "markdown",
      "source": "Using data from http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"
    },
    {
      "metadata": {
        "_cell_guid": "b5fec7be-5525-4c45-8f9c-cb4b2c112be6",
        "_uuid": "c9f7d8da6a863a9d9bb3050e2aa4745ec26dd54a"
      },
      "cell_type": "markdown",
      "source": "![](https://i.imgur.com/jZqpV51.png)\n\nFigure S6. Illustrative Examples of Chest X-Rays in Patients with Pneumonia, Related to Figure 6\nThe normal chest X-ray (left panel) depicts clear lungs without any areas of abnormal opacification in the image. Bacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in this case in the right upper lobe (white arrows), whereas viral pneumonia (right) manifests with a more diffuse ‘‘interstitial’’ pattern in both lungs.\nhttp://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n"
    },
    {
      "metadata": {
        "_cell_guid": "8ac5aba9-de61-4c1a-9197-0806bcd223b5",
        "_uuid": "7f9547358c9cebf0a42166738c7dff19b16ff916"
      },
      "cell_type": "markdown",
      "source": "*Step 1: Import Modules*"
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "_cell_guid": "42b35245-93b6-45ed-bcf8-d9ff22473269",
        "_kg_hide-input": true,
        "_uuid": "3d3bc91774b6b395666c22dc2cca97af6d5dcbe3",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nfrom scipy import ndimage\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization, SeparableConv2D, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.resnet50 import ResNet50\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n#from keras.applications.mobilenet import MobileNet\n#from sklearn.metrics import roc_auc_score\n#from sklearn.metrics import roc_curve\n#from sklearn.metrics import auc\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "59dcc7b7-740e-4ecf-a8ac-c86e66ea3511",
        "_uuid": "be534235b529040019854353c2f3a373300cfb20"
      },
      "cell_type": "markdown",
      "source": "*Step 2: Load Data*\n\nImages must be resized to match expected model inputs."
    },
    {
      "metadata": {
        "_cell_guid": "86a1fb25-c9b2-41fe-8bc3-01d91f7054bb",
        "_uuid": "22c127e3183a316ca314946688e21db95a7dc4ca",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_dir = \"../input/chest-xray-pneumonia/chest_xray/chest_xray/train/\"\ntest_dir =  \"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/\"\ndef get_data(folder):\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['NORMAL']:\n                label = 0\n            elif folderName in ['PNEUMONIA']:\n                label = 1\n            else:\n                label = 2\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n                if img_file is not None:\n                    # size to match pretrained vgg16 and inception networks\n                    img_file = skimage.transform.resize(img_file, (150, 150, 3))\n                    # size to match resnet50\n                    #img_file = skimage.transform.resize(img_file, (200, 200, 3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\n\nX_train, y_train = get_data(train_dir)\nX_test, y_test= get_data(test_dir)\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 2)\ny_testHot = to_categorical(y_test, num_classes = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9697e49e-842c-4036-ae9f-641046758573",
        "_uuid": "6a6b491f3ab910d04a2e7053eb8fb50eac2713c3"
      },
      "cell_type": "markdown",
      "source": "*Step 3: Vizualize Data*"
    },
    {
      "metadata": {
        "_cell_guid": "a8175a28-50e7-4ef0-bdce-7d45de647677",
        "_uuid": "23b61840058209bb797359e6b9eed686b5ecf3ac"
      },
      "cell_type": "markdown",
      "source": "The min/max pixel values are already scaled between 0 and 1 because its black and white."
    },
    {
      "metadata": {
        "_cell_guid": "1abb596c-5c13-4d48-aaf2-d4683f822511",
        "_uuid": "eb614459b47542a02b0bf9241d778922d6800a88",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "normal_images = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/**')\npneumonia_images = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/**')\ndef plotHistogram(a, label):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    histo = plt.subplot(1,2,2)\n    histo.set_title(label)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5)\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5)\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5)\n\n\nplotHistogram(cv2.imread(normal_images[0]), \"NORMAL\")\nplotHistogram(cv2.imread(pneumonia_images[0]), \"PNEUMONIA\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "199e4466-a943-4de8-892e-c9ba068265c8",
        "_uuid": "16f6d7087f9523d1633ecf65985c091ce8d64ba7"
      },
      "cell_type": "markdown",
      "source": "20 images from category \"No Pneumonia\""
    },
    {
      "metadata": {
        "_cell_guid": "cd7271b9-db7e-4077-b7e0-82a7d182a223",
        "_uuid": "2be42c9523cd6e2434a43ac5515736101971aa9e",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"No Pneumonia\")\nmultipleImages = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ec88b5d9-327f-4089-b3aa-3c4045d76025",
        "_uuid": "472d6a6c0a604aac9017b03bf8e885adc19aa90c"
      },
      "cell_type": "markdown",
      "source": "20 images from category \"Yes Pneumonia\""
    },
    {
      "metadata": {
        "_cell_guid": "f5334023-e1cc-4b1e-a8fc-64237115e88f",
        "_uuid": "e8cfa379815959d01f5d78113e4ebd6e2d5f4084",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Yes Pneumonia\")\nmultipleImages = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "acafe27f-6c13-4091-9ce0-907c5784eb79",
        "_uuid": "6384bf60c740fc5cc97c90c6bb4a170e294210b2",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "map_characters = {0: 'No Pneumonia', 1: 'Yes Pneumonia'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"]=y_train\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9414e78c-08b4-4c5c-b8df-73240e7c1350",
        "_uuid": "83b4d12d206885ead7b84145c25027942a0f5b65"
      },
      "cell_type": "markdown",
      "source": "*Step 4: Define Helper Functions*"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "5c2b5fc4-e1af-4dfe-a928-8a8076c73d59",
        "_uuid": "992129dbd3c7695bdd2e2497a6a56da0227c8c0d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Helper Functions  Learning Curves and Confusion Matrix\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6d9c6929-3f64-4d4e-a82b-362602641156",
        "_uuid": "46be241c508bd8f733fd41b84fa0d4d12ff67b33"
      },
      "cell_type": "markdown",
      "source": "*Step 5: Evaluate Classification Models*"
    },
    {
      "metadata": {
        "_cell_guid": "3dac612a-0543-47a7-b9be-9a45820b0473",
        "_uuid": "7bb6dff5a30e1644bbfffa0a7c7b5992df5a494c"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ VGG16 Convolutional Network or Inception V3\n\nKeras comes with a bunch of pre-trained models for various uses. You can check them out here: https://keras.io/applications/\nThis is a convinience function which allows us to easily try out different models.\n\nVGG16:\nhttps://www.cs.toronto.edu/~frossard/post/vgg16/\n![VGG16](https://www.cs.toronto.edu/~frossard/post/vgg16/vgg16.png)\n\nInception v3:\nhttps://cloud.google.com/tpu/docs/inception-v3-advanced\n![Inception v3](https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/img/4a077a942db85cb3.png)\n\nAdding a new node to the last layer of the pre-trained model and observing the change in results.\nThe original pretrained network here is actually already doing that when it adds a top layer, so we will try something slightly different.\nFor more info on these see: https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975\nor any other information on fine tuning pretrained Keras models.\n\n(As suggested by Sageev)\n\nHere is a comparison of ReLU and Softmax:\nhttps://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions\n\nSoftmax is generally good for classifying inputs with multiple possible outputs (ex: classifying which of the 9 possible hand written digits we are seeing). The output of a softmax can be seen as a probability distribution across categories.\n\nThe sigmoid activation function is more commonly used to two-class problems such as this so we would expect it to perform better, see: https://stats.stackexchange.com/questions/233658/softmax-vs-sigmoid-function-in-logistic-classifier"
    },
    {
      "metadata": {
        "scrolled": true,
        "_cell_guid": "da473dc4-7e79-4be0-97aa-c7cca6e8aa43",
        "_uuid": "1b8d8acad18ea6c063c61c50d84c5c65f8678b21",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "map_characters1 = {0: 'No Pneumonia', 1: 'Yes Pneumonia'}\nclass_weight_all_data = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path_inception_v3 = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path_resnet50 = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\npretrained_model_inception_v3 = InceptionV3(weights = weight_path_inception_v3, include_top=False, input_shape=(150, 150, 3))\npretrained_model_resnet50 = ResNet50(weights = weight_path_resnet50, include_top=False, input_shape=(200, 200, 3))\noptimizer_RMS = keras.optimizers.RMSprop(lr=0.0001)\n\ndef pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrainedmodel # Topless\n    # Add sofmax top layer\n#     x = base_model.output\n#     x = Flatten()(x)\n#     predictions = Dense(numclasses, activation='softmax')(x)\n#     model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # Add sigmoid top layer\n    x = base_model.output\n    x = Flatten()(x)\n    top_layer_relu = Dense(numclasses, activation='relu')(x)\n    top_layer_sigmoid = Dense(2, activation='sigmoid')(top_layer_relu)\n    model = Model(inputs=base_model.input, outputs=top_layer_sigmoid)\n    \n    # Train top layer\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    # Fit model\n    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n    # Evaluate model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    test_loss, test_acc = model.evaluate(xtest,ytest, verbose=0)\n    print(\"Test set loss: \", test_loss)\n    print(\"Test set accuracy: \", test_acc)\n    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n    plt.show()\n    return model\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1fe25116e6c191b1ab63fe57b89573aabc612967"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ VGG16 Convolutional Network (must be done with (150,150,3) scaled input)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe9c778567b8a489a52f32319edd2b9dafe1902d",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,15,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89c8d45ab1c9eecdb88d3e91eb72dc4d1887c383"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ VGG16 Convolutional Network (10 epochs)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5ae891b3c9cf84f8a8108d7ccbceeb5708f257a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,10,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1694b4501783a4acf444e8491cbef7c7719a0d4"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ Resnet50 Convolutional Network\nThis was seen as a popular xray classifier in research.\nThis was abysmal on test data. 95% on training, but 50% on test. Possibly due to how the images are scaled. \n\nLook into this. https://stackoverflow.com/questions/47157526/resnet-100-accuracy-during-training-but-33-prediction-accuracy-with-the-same\n\n![resnet50 classifier output](https://i.imgur.com/4GrvEVV.png)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4541e97fa3bd557f2c5539a28ce91697b5f2ba4",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_resnet50,weight_path_resnet50,class_weight_all_data,2,10,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "44c3544b-1d5d-4408-94ce-a8ecb89bdb20",
        "_uuid": "8abab1928d91eda44781f0dbc194f1e80fb8586a"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ InceptionV3 Convolutional Network\n\nCurrently this has great training accuracy, but lackluster performance on the test data. This is a likely candidate for overfitting. "
    },
    {
      "metadata": {
        "_cell_guid": "54f91c61-c425-4c17-a5f0-1944811f56cf",
        "_uuid": "893764b26b1dbd1bf7bedbbf811e7ec029967721",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_inception_v3,weight_path_inception_v3,class_weight_all_data,2,150,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7f8ec99a-d1e1-4eea-adfb-2c360145b490",
        "_uuid": "be4341dd9681e8386feebeb374f261aad0dc4f9f"
      },
      "cell_type": "markdown",
      "source": "*Step 6: Evaluate Undersampling Strategy*"
    },
    {
      "metadata": {
        "_cell_guid": "a6118296-3d6e-43a7-b07b-ce3c58d61d01",
        "_uuid": "71ac47756f79e022764c16bfc7810a0537b7d593"
      },
      "cell_type": "markdown",
      "source": "The goal is to get rid of the class imbalance issues.  Oversampling with data augmentation (e.g. [SMOTE](http://contrib.scikit-learn.org/imbalanced-learn/stable/over_sampling.html)) would be preferable to undersampling but undersampling is faster.\n\nThe imbalance is caused by the fact that the data has a lot more positive 'Yes Pneumonia' examples than negative. This means we can undersample to remove some of the positive examples and even out the data.\nMore info here: http://www.chioka.in/class-imbalance-problem/"
    },
    {
      "metadata": {
        "scrolled": true,
        "_cell_guid": "a86b7d6e-f4d3-4c8c-9807-c92897e875a0",
        "_uuid": "212b47546c7033f8edf8480db2eae7b6a5e39cc4",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Deal with imbalanced class sizes below\n# Make Data 1D for compatability upsampling methods\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\nY_train = y_train\nY_test = y_test\n#ros = RandomOverSampler(ratio='auto')\nros = RandomUnderSampler(ratio='auto')\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\nX_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\nY_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n# Make Data 2D again\nfor i in range(len(X_trainRos)):\n    height, width, channels = 150,150,3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\nfor i in range(len(X_testRos)):\n    height, width, channels = 150,150,3\n    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n# Plot Label Distribution\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\ndistRos = lab.value_counts()\nsns.countplot(labRos)\nprint(dict_characters)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "34ebec12-65c4-4fd8-b958-47e0b71ec6d4",
        "_uuid": "67f4555b0de9afd8f09c2ebe0a207ef7c9b3ff3b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "class_weight_all_data = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\nprint(\"Old Class Weights: \",class_weight_all_data)\nclass_weight_undersampled = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)\nprint(\"New Class Weights: \",class_weight_undersampled)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "915df205-6986-40dd-96be-b11f4f468556",
        "_uuid": "ab3d217e144271dfb0551a99d192c8caa3814483"
      },
      "cell_type": "markdown",
      "source": "*Step 7: Evaluate Final Model*"
    },
    {
      "metadata": {
        "_cell_guid": "80d89d7d-7838-4908-a011-b0db212708d9",
        "_uuid": "b422b239db3775af921bb460a688caa1b991e1a4"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ VGG16 Convolutional Network"
    },
    {
      "metadata": {
        "_cell_guid": "ce65ba0c-e811-4f52-86e7-5f78da2170b1",
        "_uuid": "a247357b8fe07d683aec3cfac1ec9b506ddc4846",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_undersampled,2,25,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f3e06981-9033-404a-98db-8ec5b2bcae1d",
        "_uuid": "05e91fb451d5882a1ef6a1110b0d3f9f12fad9b0"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ InceptionV3 Convolutional Network"
    },
    {
      "metadata": {
        "_cell_guid": "3aa204e6-de96-46e6-8663-2cb3bc0f119f",
        "_uuid": "8fdce72c1fb9ddfca8e9c90dc719eb600eb169bd",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_inception_v3,weight_path_inception_v3,class_weight_undersampled,2,25,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e7a5b8ae-db73-4faf-ba18-cf8e4de95f3e",
        "_uuid": "dfcda4c8cd3604ba52baa38654e9e115e745ddd5"
      },
      "cell_type": "markdown",
      "source": " We were able to detect pneumonia in x-ray images with an accuracy rate of approximately 85%. "
    },
    {
      "metadata": {
        "_uuid": "8796c2150429f0d4fba69826996bf8f9475da9d0"
      },
      "cell_type": "markdown",
      "source": "As expected the sigmoid activation function seems to be classifying better (expand on why).\n\nSeems to top out around 10-12 epochs (why?).\n\nRandomly can have really bad classification, look into this."
    },
    {
      "metadata": {
        "_uuid": "0e4fed4d0877a7b374799066b9fc37e677d2f433"
      },
      "cell_type": "markdown",
      "source": "# Testing Pre-processing Sharpened Data"
    },
    {
      "metadata": {
        "_uuid": "91042c48001030f1c6d0d16ec8ab90579c3ee82e"
      },
      "cell_type": "markdown",
      "source": "Load data as sharpened images to test results...\n\nUsing image sharpening from: https://www.scipy-lectures.org/advanced/image_processing/auto_examples/plot_sharpen.html"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fa8ece6ec5c3a594e03bac58c9db5ab68389b1f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_dir = \"../input/chest-xray-pneumonia/chest_xray/chest_xray/train/\"\ntest_dir =  \"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/\"\ndef get_sharpened_data(folder):\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['NORMAL']:\n                label = 0\n            elif folderName in ['PNEUMONIA']:\n                label = 1\n            else:\n                label = 2\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (150, 150, 3))\n                    \n                    blurred_img = ndimage.gaussian_filter(img_file, 3)\n                    filter_blurred_img = ndimage.gaussian_filter(blurred_img, 1)\n                    # tried out some different alpha values, this seems like a good one for not introducing artifacts\n                    alpha = 15\n                    sharpened = blurred_img + alpha * (blurred_img - filter_blurred_img)\n    \n                    img_arr = np.asarray(sharpened)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\nsharpened_X_train, sharpened_y_train = get_sharpened_data(train_dir)\nsharpened_X_test, sharpened_y_test= get_sharpened_data(test_dir)\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\nsharpened_y_trainHot = to_categorical(sharpened_y_train, num_classes = 2)\nsharpened_y_testHot = to_categorical(sharpened_y_test, num_classes = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36bd12e2a98bbeba24a003e61da33de51a0fe85b"
      },
      "cell_type": "markdown",
      "source": "Transfer learning w/ VGG16,  sharpened images\n\nno undersampling (yet)\n\nLooks like, it has a negative effect on classification, probably due to the artifacts that are introduced by sharpening."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18abd03a41dbcac66996ab785b98d3b70d5a8f2e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "class_weight_sharpened = class_weight.compute_class_weight('balanced', np.unique(sharpened_y_train), sharpened_y_train)\npretrainedNetwork(sharpened_X_train, sharpened_y_trainHot, sharpened_X_test, sharpened_y_testHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_sharpened,2,10,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f768da4ac732b80be97f4c62623133679f7d3df"
      },
      "cell_type": "markdown",
      "source": "# Stripping and specializing layers\n## Important: Currently just working on this with vgg16 in mind.\n\nLeNet-style models, stacks of convolutions for feature extraction and max-pooling operations for spatial sub-sampling\n\nTODO: Testing layer 5 batch normalization."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2fe7ba5eff426b0ad0984677d55bc666af78258c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "optimizer_adam = keras.optimizers.RMSprop(lr=0.0001, decay=1e-5)\n\n# For training model after stripping layers\ndef strippedPretrainedNetwork(xtrain,ytrain,xtest,ytest,model,classweight,numepochs,optimizer,labels):\n    \n    model.compile(loss='binary_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    \n    # Fit model\n    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n    # Evaluate model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n    plt.show()\n    return model\n\n\ndef oneStrippedLayer(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrainedmodel # Topless\n    \n    # Train top layer only\n    for layer in base_model.layers:\n        layer.trainable = False\n    # Remove the 5th block entirely\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    out = base_model.layers[-1].output\n    #base_model.summary()\n    \n    x = out\n    # Layer 5\n    conv5_1 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_1')(x)\n    bn5_1 = BatchNormalization(name='bn5_1')(conv5_1)\n    conv5_2 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_2')(bn5_1)\n    bn5_2 = BatchNormalization(name='bn5_2')(conv5_2)\n    conv5_3 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_3')(bn5_2)\n    pool5 = MaxPooling2D((2,2), name='pool5')(conv5_3)\n    \n    # Output layer\n    flattened = Flatten(name='flatten')(pool5)\n    top_layer_relu = Dense(numclasses, activation='relu', name='fully_con_1')(flattened)\n    #top_layer_dropout = Dropout(0.7, name='dropout')(top_layer_relu)\n    #top_layer_softmax = Dense(2, activation='softmax', name='fully_con_2')(top_layer_dropout)\n    #top_layer_sigmoid = Dense(2, activation='sigmoid')(top_layer_dropout)\n    top_layer_sigmoid = Dense(2, activation='sigmoid')(top_layer_relu)\n\n    #model = Model(inputs=base_model.input, outputs=top_layer_softmax)\n    model = Model(inputs=base_model.input, outputs=top_layer_sigmoid)\n    return strippedPretrainedNetwork(xtrain,ytrain,xtest,ytest,model,classweight,numepochs,optimizer,labels)\n\n\ndef twoStrippedLayers(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrainedmodel # Topless\n    \n    # Train new layers only\n    for layer in base_model.layers:\n        layer.trainable = False\n    # Remove the 5th block entirely\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    # Remove the 4th block entirely\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    base_model.layers.pop()\n    out = base_model.layers[-1].output\n    #base_model.summary()\n    \n    x = out\n    # Layer 4\n    conv4_1 = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='conv4_1')(x)\n    bn4_1 = BatchNormalization(name='bn4_1')(conv4_1)\n    conv4_2 = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='conv4_2')(bn4_1)\n    bn4_2 = BatchNormalization(name='bn4_2')(conv4_2)\n    conv4_3 = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='conv4_3')(bn4_2)\n    pool4 = MaxPooling2D((2,2), name='pool4')(conv4_3)\n    \n    # Layer 5\n    conv5_1 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_1')(pool4)\n    bn5_1 = BatchNormalization(name='bn5_1')(conv5_1)\n    conv5_2 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_2')(bn5_1)\n    bn5_2 = BatchNormalization(name='bn5_2')(conv5_2)\n    conv5_3 = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='conv5_3')(bn5_2)\n    pool5 = MaxPooling2D((2,2), name='pool5')(conv5_3)\n    \n    # Output layer\n    flattened = Flatten(name='flatten')(pool5)\n    top_layer_relu = Dense(numclasses, activation='relu', name='fully_con_1')(flattened)\n    top_layer_sigmoid = Dense(2, activation='sigmoid')(top_layer_relu)\n\n    model = Model(inputs=base_model.input, outputs=top_layer_sigmoid)\n    return strippedPretrainedNetwork(xtrain,ytrain,xtest,ytest,model,classweight,numepochs,optimizer,labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d1bb48126aeec04aef86216714f43c97e89c7fe5"
      },
      "cell_type": "markdown",
      "source": "Transfer learn VGG16 w/ a trainable batch norm layer\n\nOutputs of 100 epochs and RMS prop optimizer:\n![100 epochs](https://i.imgur.com/IA0xkwb.png)\n\nOutputs of 400 epochs and Adam optimizer in repo images folder."
    },
    {
      "metadata": {
        "_uuid": "59e65140ef6cb9a0fd4c11a23cbb1e824d96b9bd"
      },
      "cell_type": "markdown",
      "source": "### VGG16 with undersampling stripping 1 layer:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8198e45ae4c40b84d6c47debaabf2c7400545703",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Redeclare the model so that we know which layers we are popping\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\noneStrippedLayer(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_undersampled,2,15,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "29f1fdf3f1705f553ec3efc2bcbb1ad851e26e4f"
      },
      "cell_type": "markdown",
      "source": "### VGG16 with all data stripping 1 layer:"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "39b866b4f2c0815a50abda3f8323160dbc4693a8"
      },
      "cell_type": "code",
      "source": "# Redeclare the model so that we know which layers we are popping\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\noneStrippedLayer(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,30,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "465e2a4499ac9cd929d6dafc0bd02782b63f2386"
      },
      "cell_type": "markdown",
      "source": "### VGG16 strip 2 layers and test/train on undersampled data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd72524b071310c029ea41bc5b5db1db02650175",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Redeclare the model so that we know which layers we are popping\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\ntwoStrippedLayers(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,80,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b00c98f7d12e9da3fa5ec9ca489323cef2f79f32"
      },
      "cell_type": "markdown",
      "source": "### VGG16 strip 2 layers and test/train on all data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c81348ac8dd0b462f12d2118e2ea537b7e424e01",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Redeclare the model so that we know which layers we are popping\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\ntwoStrippedLayers(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,50,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "969ef5656af6c09e65c6a353cfce97c8bd01d297"
      },
      "cell_type": "markdown",
      "source": "# Fine Tuning Inception V3\n\nDue to the branching nature of InceptionV3 we cannot just pop off layers as we could with VGG16. Instead truncate Inception by adding a new fully conneceted layer as in: https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n"
    },
    {
      "metadata": {
        "_uuid": "3f756478655586670e84505b9658379b4174a524"
      },
      "cell_type": "markdown",
      "source": "# Data Augmentation\nWith our relatively small amount of data using data augmentation to create some more training examples should help our model generalize better.\n\nHelpful links:\n\nhttps://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n\nhttps://keras.io/preprocessing/image/\n\nhttps://machinelearningmastery.com/image-augmentation-deep-learning-keras/"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "156a10b4d2955d43f078e3613f5303f0006ba2cd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_datagen = ImageDataGenerator(\n        rotation_range=10, # degree range to randomly rotate photos\n        width_shift_range=0.1, # random horizontal rotations\n        height_shift_range=0.1, # random vertical rotations\n        zoom_range=0.2, # random zoom on pictures\n        horizontal_flip=True, # randomly flip horizontally\n        fill_mode='nearest')\n\ntrain_datagen.fit(X_train)\n\nfor X_batch, y_batch in train_datagen.flow(X_train, y_train, batch_size=9):\n    # create a grid of 3x3 images\n    for i in range(0, 9):\n        plt.subplot(330 + 1 + i)\n        plt.imshow(X_batch[i])\n    plt.show()\n    break",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "6c00f9038400238c52c465f22717596226cb2807",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# redeclaring these here so we dont need to run other training code if we dont want to\nmap_characters1 = {0: 'No Pneumonia', 1: 'Yes Pneumonia'}\nclass_weight_all_data = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nweight_path_vgg16 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path_inception_v3 = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path_resnet50 = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_vgg16 = VGG16(weights = weight_path_vgg16, include_top=False, input_shape=(150, 150, 3))\npretrained_model_inception_v3 = InceptionV3(weights = weight_path_inception_v3, include_top=False, input_shape=(150, 150, 3))\npretrained_model_resnet50 = ResNet50(weights = weight_path_resnet50, include_top=False, input_shape=(200, 200, 3))\noptimizer_RMS = keras.optimizers.RMSprop(lr=0.0001)\n\ndef augmentedPretrainedNetwork(xtrain,ytrain,xtest,ytest,model,classweight,numepochs,optimizer,labels):\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    # Fit model\n    history = model.fit_generator(train_datagen.flow(xtrain, ytrain, batch_size=32), epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n    # Evaluate model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    test_loss, test_acc = model.evaluate(xtest,ytest, verbose=0)\n    print(\"Test set loss: \", test_loss)\n    print(\"Test set accuracy: \", test_acc)\n    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n    plt.show()\n    return model\n\ndef augmentedPretrainedOutputNode(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrainedmodel # Topless\n    # Train top layer only\n    for layer in base_model.layers:\n        layer.trainable = False\n    # Add sofmax top layer\n#     x = base_model.output\n#     x = Flatten()(x)\n#     predictions = Dense(numclasses, activation='softmax')(x)\n#     model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # Add sigmoid top layer\n    x = base_model.output\n    x = Flatten()(x)\n    top_layer_relu = Dense(numclasses, activation='relu')(x)\n    top_layer_sigmoid = Dense(2, activation='sigmoid')(top_layer_relu)\n    model = Model(inputs=base_model.input, outputs=top_layer_sigmoid)\n    return augmentedPretrainedNetwork(xtrain,ytrain,xtest,ytest,model,classweight,numepochs,optimizer,labels)\n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "60381c0f9586f52117aee25c06ed233bf39b33f8"
      },
      "cell_type": "markdown",
      "source": "Run 50 iterations on a pretrained VGG16 with training data augmentation only."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e61c8f4fde6ad587e9a64d1fe793d30fe0c1b7d",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "augmentedPretrainedOutputNode(X_train, y_trainHot, X_test, y_testHot,pretrained_model_vgg16,weight_path_vgg16,class_weight_all_data,2,15,optimizer_RMS,map_characters1)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}